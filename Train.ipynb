{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "Toxic_Train.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEGjA5vXf7xk",
        "outputId": "e8b68921-4d15-46d3-8885-a74c5eefc9f2"
      },
      "source": [
        "!pip install catboost"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting catboost\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/47/80/8e9c57ec32dfed6ba2922bc5c96462cbf8596ce1a6f5de532ad1e43e53fe/catboost-0.25.1-cp37-none-manylinux1_x86_64.whl (67.3MB)\n",
            "\u001b[K     |████████████████████████████████| 67.3MB 57kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (4.4.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-0.25.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8hjGX_2gTp_",
        "outputId": "598897d9-1d5e-419e-e36e-effebe4faf82"
      },
      "source": [
        "!pip install nltk"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VB68mww4k0Vd",
        "outputId": "b19997a7-f00b-4e48-c0de-1206fb1c8e4c"
      },
      "source": [
        "!pip install mlxtend"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.7/dist-packages (0.14.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from mlxtend) (56.1.0)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (0.22.2.post1)\n",
            "Requirement already satisfied: pandas>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.19.5)\n",
            "Requirement already satisfied: matplotlib>=1.5.1 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (3.2.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->mlxtend) (1.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.17.1->mlxtend) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.17.1->mlxtend) (2018.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (0.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.17.1->mlxtend) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxlG-h_Df1GE",
        "outputId": "b0438fc5-d50c-4b28-939d-3c262f5c6c93"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import nltk\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import SnowballStemmer\n",
        "nltk.download('punkt')\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import precision_score, recall_score, precision_recall_curve\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import plot_precision_recall_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from catboost import CatBoostClassifier\n",
        "from mlxtend.classifier import EnsembleVoteClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCD78S3wt64e"
      },
      "source": [
        "with open(\"dataset_ok.txt\", \"r+\") as file:\n",
        "  file_readen = file.read().split(\"\\n\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBf-6mtKuZHZ"
      },
      "source": [
        "labels = list(map(lambda x: list(map(lambda y: y[9 :], x.split(\" \")[0].split(\",\"))), file_readen))[: -1]\n",
        "text = list(map(lambda x: \" \".join(x.split(\" \")[1 :]), file_readen))[: -1]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_3hvN-HvK9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b46c1d8-8119-4cb5-813f-862f2d9c2ea0"
      },
      "source": [
        "df = pd.DataFrame(np.array([labels, text]).T, columns = [\"label\", \"text\"])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_N1wmE7-CH6"
      },
      "source": [
        "def onehot(series, unique):\n",
        "  series_new = pd.DataFrame(data = np.array([[0 for j in range(len(series))] for i in range(len(unique))]).T ,columns = unique)\n",
        "  for elIndex in range(len(series)):\n",
        "      for el_class in series.iloc[elIndex]: series_new[el_class].iloc[elIndex] = 1\n",
        "  return series_new"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCx0qJ74877B"
      },
      "source": [
        "df_onehoted = onehot(df.label, ['NORMAL', 'INSULT', 'THREAT', 'OBSCENITY'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glhUQXMMC65S",
        "outputId": "e7c57a2c-3651-49c1-f74b-d8efab905ac9"
      },
      "source": [
        "df_onehoted.INSULT.value_counts()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    211464\n",
              "1     36826\n",
              "Name: INSULT, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQEXkgYwDI_U",
        "outputId": "914c71a9-7af2-43f2-d4cb-12c7860c33f2"
      },
      "source": [
        "df_onehoted.THREAT.value_counts()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    236263\n",
              "1     12027\n",
              "Name: THREAT, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hzyezw2FDNKx",
        "outputId": "ac768bc4-3ce1-496f-aa5a-5a1e1a03b68d"
      },
      "source": [
        "df_onehoted.OBSCENITY.value_counts()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    244029\n",
              "1      4261\n",
              "Name: OBSCENITY, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "_3v1yXn6DmeJ",
        "outputId": "8ed1bc6c-2607-4108-cbaf-d60a4fba6b71"
      },
      "source": [
        "df_onehoted"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NORMAL</th>\n",
              "      <th>INSULT</th>\n",
              "      <th>THREAT</th>\n",
              "      <th>OBSCENITY</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248285</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248286</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248287</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248288</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248289</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>248290 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        NORMAL  INSULT  THREAT  OBSCENITY\n",
              "0            0       1       0          0\n",
              "1            1       0       0          0\n",
              "2            1       0       0          0\n",
              "3            1       0       0          0\n",
              "4            1       0       0          0\n",
              "...        ...     ...     ...        ...\n",
              "248285       1       0       0          0\n",
              "248286       0       1       0          0\n",
              "248287       1       0       0          0\n",
              "248288       1       0       0          0\n",
              "248289       1       0       0          0\n",
              "\n",
              "[248290 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzXn9pVIf1GH"
      },
      "source": [
        "df_2ch = pd.read_csv(\"labeled.csv\")\n",
        "df_2ch['toxic'] = df_2ch['toxic'].astype(int)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "HwF470tp-pHH",
        "outputId": "8fa37d7d-a50d-4a22-ffe3-c36743f217c5"
      },
      "source": [
        "df_2ch"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Верблюдов-то за что? Дебилы, бл...\\n</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Хохлы, это отдушина затюканого россиянина, мол...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Собаке - собачья смерть\\n</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Страницу обнови, дебил. Это тоже не оскорблени...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>тебя не убедил 6-страничный пдф в том, что Скр...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14407</th>\n",
              "      <td>Вонючий совковый скот прибежал и ноет. А вот и...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14408</th>\n",
              "      <td>А кого любить? Гоблина тупорылого что-ли? Или ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14409</th>\n",
              "      <td>Посмотрел Утомленных солнцем 2. И оказалось, ч...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14410</th>\n",
              "      <td>КРЫМОТРЕД НАРУШАЕТ ПРАВИЛА РАЗДЕЛА Т.К В НЕМ Н...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14411</th>\n",
              "      <td>До сих пор пересматриваю его видео. Орамбо кст...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14412 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 comment  toxic\n",
              "0                   Верблюдов-то за что? Дебилы, бл...\\n      1\n",
              "1      Хохлы, это отдушина затюканого россиянина, мол...      1\n",
              "2                              Собаке - собачья смерть\\n      1\n",
              "3      Страницу обнови, дебил. Это тоже не оскорблени...      1\n",
              "4      тебя не убедил 6-страничный пдф в том, что Скр...      1\n",
              "...                                                  ...    ...\n",
              "14407  Вонючий совковый скот прибежал и ноет. А вот и...      1\n",
              "14408  А кого любить? Гоблина тупорылого что-ли? Или ...      1\n",
              "14409  Посмотрел Утомленных солнцем 2. И оказалось, ч...      0\n",
              "14410  КРЫМОТРЕД НАРУШАЕТ ПРАВИЛА РАЗДЕЛА Т.К В НЕМ Н...      1\n",
              "14411  До сих пор пересматриваю его видео. Орамбо кст...      0\n",
              "\n",
              "[14412 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ek6T96vRf1GI",
        "outputId": "1ec3a041-d9d0-40a0-c163-09dbba29534d"
      },
      "source": [
        "snowball = SnowballStemmer(language=\"russian\")\n",
        "nltk.download('stopwords')\n",
        "russian_stop_words = stopwords.words(\"russian\")\n",
        "\n",
        "def tokenize_sentence(sentence: str, remove_stop_words: bool = True):\n",
        "    tokens = word_tokenize(sentence, language=\"russian\")\n",
        "    tokens = [i for i in tokens if i not in string.punctuation]\n",
        "    if remove_stop_words:\n",
        "        tokens = [i for i in tokens if i not in russian_stop_words]\n",
        "    tokens = [snowball.stem(i) for i in tokens]\n",
        "    return tokens"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2y2Dcxc0m5T"
      },
      "source": [
        "X_train_ins, X_test_ins, y_train_ins, y_test_ins = train_test_split(df.text, df_onehoted.INSULT, test_size=0.33, random_state=42)\n",
        "X_train_thr, X_test_thr, y_train_thr, y_test_thr = train_test_split(df.text, df_onehoted.THREAT, test_size=0.33, random_state=42)\n",
        "X_train_obs, X_test_obs, y_train_obs, y_test_obs = train_test_split(df.text, df_onehoted.OBSCENITY, test_size=0.33, random_state=42)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCpz8Mfi279K"
      },
      "source": [
        "models_pipeline = {\n",
        "    \"INS\": Pipeline([(\"vectorizer\", TfidfVectorizer(tokenizer=tokenize_sentence)), (\"model\", LogisticRegression(random_state=42, C=10))]),\n",
        "    \"THR\": Pipeline([(\"vectorizer\", TfidfVectorizer(tokenizer=tokenize_sentence)), (\"model\", LogisticRegression(random_state=42, C=10))]), \n",
        "    \"OBS\": Pipeline([(\"vectorizer\", TfidfVectorizer(tokenizer=tokenize_sentence)), (\"model\", LogisticRegression(random_state=42, C=10))])\n",
        "    }"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Em5Pb33E3OUy",
        "outputId": "b3ad2f3e-631d-48c8-bee7-548d6ea1b3c8"
      },
      "source": [
        "models_pipeline['INS'].fit(X_train_ins, y_train_ins)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vectorizer',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_patt...w+\\\\b',\n",
              "                                 tokenizer=<function tokenize_sentence at 0x7fa6bdfcac20>,\n",
              "                                 use_idf=True, vocabulary=None)),\n",
              "                ('model',\n",
              "                 LogisticRegression(C=10, class_weight=None, dual=False,\n",
              "                                    fit_intercept=True, intercept_scaling=1,\n",
              "                                    l1_ratio=None, max_iter=100,\n",
              "                                    multi_class='auto', n_jobs=None,\n",
              "                                    penalty='l2', random_state=42,\n",
              "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                    warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJnAtJM_Fvwn",
        "outputId": "62e198b3-3ee8-447a-89ac-90589a82da64"
      },
      "source": [
        "models_pipeline['THR'].fit(X_train_thr, y_train_thr)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vectorizer',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_patt...w+\\\\b',\n",
              "                                 tokenizer=<function tokenize_sentence at 0x7fa6bdfcac20>,\n",
              "                                 use_idf=True, vocabulary=None)),\n",
              "                ('model',\n",
              "                 LogisticRegression(C=10, class_weight=None, dual=False,\n",
              "                                    fit_intercept=True, intercept_scaling=1,\n",
              "                                    l1_ratio=None, max_iter=100,\n",
              "                                    multi_class='auto', n_jobs=None,\n",
              "                                    penalty='l2', random_state=42,\n",
              "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                    warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOuG_dusFwVp",
        "outputId": "084af0ac-170a-40dc-ac6e-ec70014af6e8"
      },
      "source": [
        "models_pipeline['OBS'].fit(X_train_obs, y_train_obs)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vectorizer',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_patt...w+\\\\b',\n",
              "                                 tokenizer=<function tokenize_sentence at 0x7fa6bdfcac20>,\n",
              "                                 use_idf=True, vocabulary=None)),\n",
              "                ('model',\n",
              "                 LogisticRegression(C=10, class_weight=None, dual=False,\n",
              "                                    fit_intercept=True, intercept_scaling=1,\n",
              "                                    l1_ratio=None, max_iter=100,\n",
              "                                    multi_class='auto', n_jobs=None,\n",
              "                                    penalty='l2', random_state=42,\n",
              "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                    warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rFhOmto3w7H",
        "outputId": "594536e5-7c61-45d8-ce71-86ca4ad8c623"
      },
      "source": [
        "print(\"Precision: {}; Recall: {}\".format(precision_score(y_true=y_test_ins, y_pred=models_pipeline['INS'].predict(X_test_ins), average = 'weighted'), recall_score(y_true=y_test_ins, y_pred=models_pipeline['INS'].predict(X_test_ins), average = 'weighted')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision: 0.9599445125554553; Recall: 0.960676625659051\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPNnRYieGGAk",
        "outputId": "47fb1bc4-a993-492d-f1a5-39349c1d1b41"
      },
      "source": [
        "print(\"Precision: {}; Recall: {}\".format(precision_score(y_true=y_test_thr, y_pred=models_pipeline['THR'].predict(X_test_thr), average = 'weighted'), recall_score(y_true=y_test_thr, y_pred=models_pipeline['THR'].predict(X_test_thr), average = 'weighted')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision: 0.9774182679964719; Recall: 0.9786784807654755\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQ_VXly8F2fd",
        "outputId": "a4cbb95f-043e-4eef-c0ad-8f90d47b1621"
      },
      "source": [
        "print(\"Precision: {}; Recall: {}\".format(precision_score(y_true=y_test_obs, y_pred=models_pipeline['OBS'].predict(X_test_obs), average = 'weighted'), recall_score(y_true=y_test_obs, y_pred=models_pipeline['OBS'].predict(X_test_obs), average = 'weighted')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision: 0.9913580079452491; Recall: 0.9919693419254052\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rc4uwWIm-yJ1",
        "outputId": "9bf55e55-8163-4b4e-f337-e0e12b4400fc"
      },
      "source": [
        "roc_auc_score(models_pipeline[\"INS\"].predict(df_2ch.comment), df_2ch.toxic)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8399818766217839"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "m-dcz7ktBYRR",
        "outputId": "be87ef0b-0148-45a7-dafd-32e262f4dcde"
      },
      "source": [
        "df_2ch.iloc[np.where(models_pipeline[\"THR\"].predict(df_2ch.comment) == 1)]"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Собаке - собачья смерть\\n</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>Что б он сам здох мразь\\n</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>Таких как ты психопатов на хуй отстреливать в ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142</th>\n",
              "      <td>Вы привели достаточно аргументов чтобы их не п...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>348</th>\n",
              "      <td>стрелять в орущее быдло\\n</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14003</th>\n",
              "      <td>Пиар параши. Сделайте этому хуесосу уже гребеш...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14107</th>\n",
              "      <td>Это моча так неугодных гнобит. Даёт бан педрюх...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14146</th>\n",
              "      <td>И кто же тебя обоссал на этот раз, россиянец?\\n</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14388</th>\n",
              "      <td>ПРОКЛЯТАЯ ДЕТОЕДСКАЯ МРАЗЬ. ГОРИ В АДУ ВЕЧНО.\\n</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14398</th>\n",
              "      <td>Моча в анимаче решила окончательно убить реакш...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>98 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 comment  toxic\n",
              "2                              Собаке - собачья смерть\\n      1\n",
              "97                             Что б он сам здох мразь\\n      1\n",
              "117    Таких как ты психопатов на хуй отстреливать в ...      1\n",
              "142    Вы привели достаточно аргументов чтобы их не п...      1\n",
              "348                            стрелять в орущее быдло\\n      1\n",
              "...                                                  ...    ...\n",
              "14003  Пиар параши. Сделайте этому хуесосу уже гребеш...      1\n",
              "14107  Это моча так неугодных гнобит. Даёт бан педрюх...      1\n",
              "14146    И кто же тебя обоссал на этот раз, россиянец?\\n      1\n",
              "14388    ПРОКЛЯТАЯ ДЕТОЕДСКАЯ МРАЗЬ. ГОРИ В АДУ ВЕЧНО.\\n      1\n",
              "14398  Моча в анимаче решила окончательно убить реакш...      1\n",
              "\n",
              "[98 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "kD0vKi0ECMJL",
        "outputId": "8e4beac4-16e3-49de-ebcf-ba4cdb9962ca"
      },
      "source": [
        "df_2ch.iloc[np.where(models_pipeline[\"OBS\"].predict(df_2ch.comment) == 1)]"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>163</th>\n",
              "      <td>о жопах Да нет, это твой свидомый мозг дорисов...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>274</th>\n",
              "      <td>мне поебать на его финансы и кто он. Не пизди,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>373</th>\n",
              "      <td>Я атеист и армянин. Просто рот твой ебал Лучше...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>374</th>\n",
              "      <td>Конечно, вы же собак ебете, блядь.\\n</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>777</th>\n",
              "      <td>Я ШЛЮХА -- ТЕТЯ СРАКА, ВАША ЗАРПЛАТА ПОНИЖЕНА....</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14195</th>\n",
              "      <td>Тебе уже предоставляется такая возможность, бе...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14231</th>\n",
              "      <td>не захотел отсасывать мракобесию И с заглотом ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14232</th>\n",
              "      <td>Соси хуй подсос единоросский\\n</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14258</th>\n",
              "      <td>Хуй соси, анимеблядь. Мать твою ебал Аноним ID...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14346</th>\n",
              "      <td>Я поглотил знание. Вы будете сосать мой хуй. С...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>106 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 comment  toxic\n",
              "163    о жопах Да нет, это твой свидомый мозг дорисов...      1\n",
              "274    мне поебать на его финансы и кто он. Не пизди,...      1\n",
              "373    Я атеист и армянин. Просто рот твой ебал Лучше...      1\n",
              "374                 Конечно, вы же собак ебете, блядь.\\n      1\n",
              "777    Я ШЛЮХА -- ТЕТЯ СРАКА, ВАША ЗАРПЛАТА ПОНИЖЕНА....      1\n",
              "...                                                  ...    ...\n",
              "14195  Тебе уже предоставляется такая возможность, бе...      1\n",
              "14231  не захотел отсасывать мракобесию И с заглотом ...      1\n",
              "14232                     Соси хуй подсос единоросский\\n      1\n",
              "14258  Хуй соси, анимеблядь. Мать твою ебал Аноним ID...      1\n",
              "14346  Я поглотил знание. Вы будете сосать мой хуй. С...      1\n",
              "\n",
              "[106 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "boGtqRbDf1GL",
        "outputId": "1c354aea-9325-43dc-9100-5efb4d94302d"
      },
      "source": [
        "model_pipeline[0].predict([\"всем привет\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['NORMAL'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YH87Tqgpf1GM"
      },
      "source": [
        "# prec, rec, thresholds = precision_recall_curve(y_test, model_pipeline.predict_proba(X_test).T[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2TwBMwqf1GN"
      },
      "source": [
        "# plot_precision_recall_curve(estimator=model_pipeline, X=test_df[\"comment\"], y=test_df[\"toxic\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IGMCc_xf1GN"
      },
      "source": [
        "# np.where(prec > 0.95)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIiOZmyy52F0",
        "outputId": "7cdae3ac-c5cd-425f-b60c-84c07e638f9d"
      },
      "source": [
        "from joblib import dump, load\n",
        "\n",
        "dump(models_pipeline[\"INS\"], 'model_ins_logistic_2.joblib')\n",
        "dump(models_pipeline[\"THR\"], 'model_thr_logistic_2.joblib')\n",
        "dump(models_pipeline[\"OBS\"], 'model_obs_logistic_2.joblib')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['model_obs_logistic_2.joblib']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAAMewPW9KcV"
      },
      "source": [
        "# model = load('model_logistic_1.joblib')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQZTZy349sqa",
        "outputId": "51e8982e-d81e-4cbd-d8c1-f0f75f0c1b2b"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['NORMAL'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    }
  ]
}