{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "Untitled.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEGjA5vXf7xk",
        "outputId": "573e9372-8109-42a1-807d-ff7c7488dabc"
      },
      "source": [
        "!pip install catboost"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting catboost\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/47/80/8e9c57ec32dfed6ba2922bc5c96462cbf8596ce1a6f5de532ad1e43e53fe/catboost-0.25.1-cp37-none-manylinux1_x86_64.whl (67.3MB)\n",
            "\u001b[K     |████████████████████████████████| 67.3MB 54kB/s \n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.1.5)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (4.4.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-0.25.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8hjGX_2gTp_",
        "outputId": "ff7f22f7-71ad-4c84-80b4-a3d324363fde"
      },
      "source": [
        "!pip install nltk"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VB68mww4k0Vd",
        "outputId": "f5de46b9-c56d-42e3-d063-70b3356b51f7"
      },
      "source": [
        "!pip install mlxtend"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.7/dist-packages (0.14.0)\n",
            "Requirement already satisfied: matplotlib>=1.5.1 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (3.2.2)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.19.5)\n",
            "Requirement already satisfied: pandas>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.1.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from mlxtend) (56.1.0)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.4.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (1.3.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->mlxtend) (1.0.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.17.1->mlxtend) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib>=1.5.1->mlxtend) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxlG-h_Df1GE",
        "outputId": "ea054daf-7b7e-4e55-d9cd-bf2bfbfd9e89"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import nltk\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import SnowballStemmer\n",
        "nltk.download('punkt')\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import precision_score, recall_score, precision_recall_curve\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import plot_precision_recall_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from catboost import CatBoostClassifier\n",
        "from mlxtend.classifier import EnsembleVoteClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCD78S3wt64e"
      },
      "source": [
        "with open(\"dataset_ok.txt\", \"r+\") as file:\n",
        "  file_readen = file.read().split(\"\\n\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBf-6mtKuZHZ"
      },
      "source": [
        "labels = list(map(lambda x: list(map(lambda y: y[9 :], x.split(\" \")[0].split(\",\"))), file_readen))[: -1]\n",
        "text = list(map(lambda x: \" \".join(x.split(\" \")[1 :]), file_readen))[: -1]"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_3hvN-HvK9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ef3209a-60c8-49b1-ad97-bb386a99cb72"
      },
      "source": [
        "df = pd.DataFrame(np.array([labels, text]).T, columns = [\"label\", \"text\"])"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_N1wmE7-CH6"
      },
      "source": [
        "def onehot(series, unique):\n",
        "  series_new = pd.DataFrame(data = np.array([[0 for j in range(len(series))] for i in range(len(unique))]).T ,columns = unique)\n",
        "  for elIndex in range(len(series)):\n",
        "      for el_class in series.iloc[elIndex]: series_new[\"{}\".format(el_class)].iloc[elIndex] = 1\n",
        "  return series_new"
      ],
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCx0qJ74877B"
      },
      "source": [
        "df_onehoted = onehot(df.label, ['NORMAL', 'INSULT', 'THREAT', 'OBSCENITY'])"
      ],
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glhUQXMMC65S",
        "outputId": "1e610733-cd8c-4798-c8a8-11f12cd857e3"
      },
      "source": [
        "df_onehoted.INSULT.value_counts()"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    211464\n",
              "1     36826\n",
              "Name: INSULT, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQEXkgYwDI_U",
        "outputId": "d76e1e2e-97e0-444e-c930-6fefcba89ab3"
      },
      "source": [
        "df_onehoted.THREAT.value_counts()"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    236263\n",
              "1     12027\n",
              "Name: THREAT, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hzyezw2FDNKx",
        "outputId": "91734d6e-efb0-4992-d069-72cce4b19656"
      },
      "source": [
        "df_onehoted.OBSCENITY.value_counts()"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    244029\n",
              "1      4261\n",
              "Name: OBSCENITY, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "_3v1yXn6DmeJ",
        "outputId": "2f8b2df7-ce01-46ef-a4f5-09260778a78d"
      },
      "source": [
        "df_onehoted"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NORMAL</th>\n",
              "      <th>INSULT</th>\n",
              "      <th>THREAT</th>\n",
              "      <th>OBSCENITY</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248285</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248286</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248287</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248288</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248289</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>248290 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        NORMAL  INSULT  THREAT  OBSCENITY\n",
              "0            0       1       0          0\n",
              "1            1       0       0          0\n",
              "2            1       0       0          0\n",
              "3            1       0       0          0\n",
              "4            1       0       0          0\n",
              "...        ...     ...     ...        ...\n",
              "248285       1       0       0          0\n",
              "248286       0       1       0          0\n",
              "248287       1       0       0          0\n",
              "248288       1       0       0          0\n",
              "248289       1       0       0          0\n",
              "\n",
              "[248290 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "l5XbiZqO2MTf",
        "outputId": "97c9422f-2cb9-4059-b03f-826d95f05321"
      },
      "source": [
        "df.iloc[248286].text"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ёбанные нубы заходите на сервер мой ник _creepro для пвп всех переебу если вы пролистываете значит вы зассали лохи все подробности в сообщениях'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzXn9pVIf1GH"
      },
      "source": [
        "# df_2ch = pd.read_csv(\"labeled.csv\")\n",
        "# df_2ch['toxic'] = df_2ch['toxic'].astype(int)\n",
        "# df[\"toxic\"] = df[\"toxic\"].apply(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ek6T96vRf1GI",
        "outputId": "3c63b195-1fb3-4ddc-9963-f4d4c890ec5c"
      },
      "source": [
        "snowball = SnowballStemmer(language=\"russian\")\n",
        "nltk.download('stopwords')\n",
        "russian_stop_words = stopwords.words(\"russian\")\n",
        "\n",
        "def tokenize_sentence(sentence: str, remove_stop_words: bool = True):\n",
        "    tokens = word_tokenize(sentence, language=\"russian\")\n",
        "    tokens = [i for i in tokens if i not in string.punctuation]\n",
        "    if remove_stop_words:\n",
        "        tokens = [i for i in tokens if i not in russian_stop_words]\n",
        "    tokens = [snowball.stem(i) for i in tokens]\n",
        "    return tokens"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2y2Dcxc0m5T"
      },
      "source": [
        "X_train_ins, X_test_ins, y_train_ins, y_test_ins = train_test_split(df.text, df_onehoted.INSULT, test_size=0.33, random_state=42)\n",
        "X_train_thr, X_test_thr, y_train_thr, y_test_thr = train_test_split(df.text, df_onehoted.THREAT, test_size=0.33, random_state=42)\n",
        "X_train_obs, X_test_obs, y_train_obs, y_test_obs = train_test_split(df.text, df_onehoted.OBSCENITY, test_size=0.33, random_state=42)"
      ],
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCpz8Mfi279K"
      },
      "source": [
        "models_pipeline = {\n",
        "    \"INS\": Pipeline([(\"vectorizer\", TfidfVectorizer(tokenizer=tokenize_sentence)), (\"model\", LogisticRegression(random_state=42, C=10))]),\n",
        "    \"THR\": Pipeline([(\"vectorizer\", TfidfVectorizer(tokenizer=tokenize_sentence)), (\"model\", LogisticRegression(random_state=42, C=10))]), \n",
        "    \"OBS\": Pipeline([(\"vectorizer\", TfidfVectorizer(tokenizer=tokenize_sentence)), (\"model\", LogisticRegression(random_state=42, C=10))])\n",
        "    }"
      ],
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Em5Pb33E3OUy",
        "outputId": "31ff5d09-a527-4eff-922b-ab053e97c554"
      },
      "source": [
        "models_pipeline['INS'].fit(X_train_ins, y_train_ins)"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vectorizer',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_patt...w+\\\\b',\n",
              "                                 tokenizer=<function tokenize_sentence at 0x7fe945916f80>,\n",
              "                                 use_idf=True, vocabulary=None)),\n",
              "                ('model',\n",
              "                 LogisticRegression(C=10, class_weight=None, dual=False,\n",
              "                                    fit_intercept=True, intercept_scaling=1,\n",
              "                                    l1_ratio=None, max_iter=100,\n",
              "                                    multi_class='auto', n_jobs=None,\n",
              "                                    penalty='l2', random_state=42,\n",
              "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                    warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJnAtJM_Fvwn",
        "outputId": "e7b23458-6d39-44a9-af8e-f816f7f03790"
      },
      "source": [
        "models_pipeline['THR'].fit(X_train_thr, y_train_thr)"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vectorizer',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_patt...w+\\\\b',\n",
              "                                 tokenizer=<function tokenize_sentence at 0x7fe945916f80>,\n",
              "                                 use_idf=True, vocabulary=None)),\n",
              "                ('model',\n",
              "                 LogisticRegression(C=10, class_weight=None, dual=False,\n",
              "                                    fit_intercept=True, intercept_scaling=1,\n",
              "                                    l1_ratio=None, max_iter=100,\n",
              "                                    multi_class='auto', n_jobs=None,\n",
              "                                    penalty='l2', random_state=42,\n",
              "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                    warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOuG_dusFwVp",
        "outputId": "d0d7f432-2d55-4d98-e72c-e04eb40a058e"
      },
      "source": [
        "models_pipeline['OBS'].fit(X_train_obs, y_train_obs)"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vectorizer',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_patt...w+\\\\b',\n",
              "                                 tokenizer=<function tokenize_sentence at 0x7fe945916f80>,\n",
              "                                 use_idf=True, vocabulary=None)),\n",
              "                ('model',\n",
              "                 LogisticRegression(C=10, class_weight=None, dual=False,\n",
              "                                    fit_intercept=True, intercept_scaling=1,\n",
              "                                    l1_ratio=None, max_iter=100,\n",
              "                                    multi_class='auto', n_jobs=None,\n",
              "                                    penalty='l2', random_state=42,\n",
              "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                    warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rFhOmto3w7H",
        "outputId": "594536e5-7c61-45d8-ce71-86ca4ad8c623"
      },
      "source": [
        "print(\"Precision: {}; Recall: {}\".format(precision_score(y_true=y_test_ins, y_pred=models_pipeline['INS'].predict(X_test_ins), average = 'weighted'), recall_score(y_true=y_test_ins, y_pred=models_pipeline['INS'].predict(X_test_ins), average = 'weighted')))"
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision: 0.9599445125554553; Recall: 0.960676625659051\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPNnRYieGGAk",
        "outputId": "47fb1bc4-a993-492d-f1a5-39349c1d1b41"
      },
      "source": [
        "print(\"Precision: {}; Recall: {}\".format(precision_score(y_true=y_test_thr, y_pred=models_pipeline['THR'].predict(X_test_thr), average = 'weighted'), recall_score(y_true=y_test_thr, y_pred=models_pipeline['THR'].predict(X_test_thr), average = 'weighted')))"
      ],
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision: 0.9774182679964719; Recall: 0.9786784807654755\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQ_VXly8F2fd",
        "outputId": "a4cbb95f-043e-4eef-c0ad-8f90d47b1621"
      },
      "source": [
        "print(\"Precision: {}; Recall: {}\".format(precision_score(y_true=y_test_obs, y_pred=models_pipeline['OBS'].predict(X_test_obs), average = 'weighted'), recall_score(y_true=y_test_obs, y_pred=models_pipeline['OBS'].predict(X_test_obs), average = 'weighted')))"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision: 0.9913580079452491; Recall: 0.9919693419254052\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LVNyF3bf1GK"
      },
      "source": [
        "# model_pipeline = Pipeline([\n",
        "#     (\"vectorizer\", TfidfVectorizer(tokenizer=tokenize_sentence)),\n",
        "#     (\"model\", LogisticRegression(random_state=42, C=10)), # C = 10\n",
        "#     # (\"model\", EnsembleVoteClassifier(clfs = [LogisticRegression(random_state=42), RandomForestClassifier(random_state = 42), SVC(probability = True)], weights = [2, 1, 1], voting = 'soft'))\n",
        "#     # (\"model\", SVC(random_state = 42, probability = True))\n",
        "#     # (\"model\", RandomForestClassifier(random_state = 42))\n",
        "#     # (\"model\", CatBoostClassifier(random_state = 42))\n",
        "# ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THocYs35f1GK"
      },
      "source": [
        "# model_pipeline.fit(train_df[\"comment\"], train_df[\"toxic\"])\n",
        "# model_pipeline.fit(X_train, y_train)"
      ],
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "boGtqRbDf1GL",
        "outputId": "1c354aea-9325-43dc-9100-5efb4d94302d"
      },
      "source": [
        "model_pipeline[0].predict([\"всем привет\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['NORMAL'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuM1P7Isf1GL",
        "outputId": "e06256ad-1e69-4156-9eef-e71d7ed1c12f"
      },
      "source": [
        "print(\"Precision: {}; Recall: {}\".format(precision_score(y_true=y_test, y_pred=model_pipeline.predict(X_test), average = 'weighted'), recall_score(y_true=y_test, y_pred=model_pipeline.predict(X_test), average = 'weighted')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Precision: 0.9530974626605782; Recall: 0.9549165822522182\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YH87Tqgpf1GM"
      },
      "source": [
        "# prec, rec, thresholds = precision_recall_curve(y_test, model_pipeline.predict_proba(X_test).T[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2TwBMwqf1GN"
      },
      "source": [
        "# plot_precision_recall_curve(estimator=model_pipeline, X=test_df[\"comment\"], y=test_df[\"toxic\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IGMCc_xf1GN"
      },
      "source": [
        "# np.where(prec > 0.95)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIiOZmyy52F0",
        "outputId": "7cdae3ac-c5cd-425f-b60c-84c07e638f9d"
      },
      "source": [
        "from joblib import dump, load\n",
        "\n",
        "dump(models_pipeline[\"INS\"], 'model_ins_logistic_2.joblib')\n",
        "dump(models_pipeline[\"THR\"], 'model_thr_logistic_2.joblib')\n",
        "dump(models_pipeline[\"OBS\"], 'model_obs_logistic_2.joblib')"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['model_obs_logistic_2.joblib']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAAMewPW9KcV"
      },
      "source": [
        "# model = load('model_logistic_1.joblib')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQZTZy349sqa",
        "outputId": "51e8982e-d81e-4cbd-d8c1-f0f75f0c1b2b"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['NORMAL'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    }
  ]
}